{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Genomics Project\n",
    "\n",
    "You can use this notebook as a code template for your MDE analysis :)\n",
    "for preprocessing used: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html#Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "I have created an h5 file with will serve as our base dataset. It contains the normalized and gene-filtered expression matrix of single-cell RNA-seq data of ~3k PBMC cells fobtained from a healthy donor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data into a ScanPy AnnData object with read()\n",
    "base_file = 'pbmc3k_base.h5ad'\n",
    "data = sc.read(base_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a high-level description of the data contained in the h5 file with print(). The *AnnData* stands for stands for annotated data matrix. This object has several attributes that we will use to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *obs* attribute is a Pandas dataframe that contains meta information about the data, such as the cell barcodes and cell type labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.obs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Now we will split our data into a training and test set. To do this, we will need the individual cell barcodes, which are the row names of the *obs* dataframe. Once we have the split assignments, we add them as a new column to the dtaframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.obs.index.to_list()\n",
    "X_train, X_test = train_test_split(list(enumerate(X)), test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=[]\n",
    "train_samples = [i[1] for i in X_train]\n",
    "for cell_id in X:\n",
    "    if cell_id in train_samples:\n",
    "        splits.append('train')\n",
    "    else:\n",
    "        splits.append('test')\n",
    "data.obs['split'] = splits\n",
    "data.obs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction Baselines\n",
    "\n",
    "Lastly, we will perform dimensionality reduction on our training and test expression matrices using PCA, tSNE, and UMAP. The expression matrix of the entire dataset can be accessed via the *X* attribute. The resulting embeddings for the training and test sets are what we will be using to perform our benchmark comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_indices = [i[0] for i in X_train]\n",
    "train_samples_indices.sort()\n",
    "test_samples_indices = [i[0] for i in X_test]\n",
    "test_samples_indices.sort()\n",
    "\n",
    "\n",
    "data.X[train_samples_indices,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "dr_pca = PCA(n_components=2, random_state=42)\n",
    "dr_pca.fit(data.X[train_samples_indices,:])\n",
    "\n",
    "pca_train = dr_pca.transform(data.X[train_samples_indices,:])\n",
    "pca_test = dr_pca.transform(data.X[test_samples_indices,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "dr_tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "##tsne_train = dr_tsne.fit_transform(data.X[train_samples_indices,:])\n",
    "tsne_train = dr_tsne.fit_transform(pca_train)\n",
    "##tsne_test = dr_tsne.fit_transform(data.X[test_samples_indices,:])\n",
    "tsne_test = dr_tsne.fit_transform(pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "dr_umap = UMAP(n_components=2, random_state=42)\n",
    "##dr_umap.fit(data.X[train_samples_indices,:])\n",
    "dr_umap.fit(pca_train)\n",
    "\n",
    "##umap_train = dr_umap.transform(data.X[train_samples_indices,:])\n",
    "umap_train = dr_umap.transform(pca_train)\n",
    "##umap_test = dr_umap.transform(data.X[test_samples_indices,:])\n",
    "umap_test = dr_umap.transform(pca_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDE Analysis - Deviation Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "mde = pymde.preserve_neighbors(\n",
    "    np.vstack([pca_train, pca_test]),\n",
    "    embedding_dim=2,\n",
    "    constraint=pymde.Standardized(),\n",
    "    repulsive_fraction=1,\n",
    "    n_neighbors=10,\n",
    "    max_distance=100,\n",
    "    verbose=True,\n",
    "    device='cpu'\n",
    ")\n",
    "embedding = mde.embed(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mde_train = embedding[:pca_train.shape[0], :]\n",
    "mde_test = embedding[pca_train.shape[0]:, :]\n",
    "\n",
    "#np.save('./mde_train.npy', mde_train)\n",
    "#np.save('./mde_test.npy', mde_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Embeddings with Minimum distortion embedding(MDE), PCA, TSNE, UMAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA on dataset \n",
    "\n",
    "\n",
    "df = data.obs[data.obs['split'] == 'train']\n",
    "df['x'] = mde_train[:,0]\n",
    "df['y'] = mde_train[:,1]\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "for ct in np.unique(df.cell_type):\n",
    "    plt.scatter(df[df.cell_type == ct].x , df[df.cell_type == ct].y , label = ct)\n",
    "\n",
    "plt.xlabel('MDE Dim 1')\n",
    "plt.ylabel('MDE Dim 2')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymde.plot(\n",
    "    mde_train,\n",
    "    color_by=data.obs[data.obs['split'] == 'train']['cell_type'],\n",
    "    color_map='tab10',\n",
    "    figsize_inches=(12, 12),\n",
    "    marker_size=15,\n",
    "    axis_limits=(-5,5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA on dataset \n",
    "\n",
    "\n",
    "df = data.obs[data.obs['split'] == 'train']\n",
    "df['x'] = pca_train[:,0]\n",
    "df['y'] = pca_train[:,1]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for ct in np.unique(df.cell_type):\n",
    "    plt.scatter(df[df.cell_type == ct].x , df[df.cell_type == ct].y , label = ct)\n",
    "\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop([df.index[df.y.argmin()], df.index[df.y.argmax()]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TSNE on dataset \n",
    "\n",
    "\n",
    "df = data.obs[data.obs['split'] == 'train']\n",
    "df['x'] = tsne_train[:,0]\n",
    "df['y'] = tsne_train[:,1]\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "for ct in np.unique(df.cell_type):\n",
    "    plt.scatter(df[df.cell_type == ct].x , df[df.cell_type == ct].y , label = ct)\n",
    "plt.xlabel(\"TSNE Dim 1\")\n",
    "plt.ylabel(\"TSNE Dim 2\")\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UMAP on dataset \n",
    "\n",
    "df = data.obs[data.obs['split'] == 'train']\n",
    "df['x'] = umap_train[:,0]\n",
    "df['y'] = umap_train[:,1]\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "for ct in np.unique(df.cell_type):\n",
    "    plt.scatter(df[df.cell_type == ct].x , df[df.cell_type == ct].y , label = ct)\n",
    "plt.xlabel(\"UMAP Dim 1\")\n",
    "plt.ylabel(\"UMAP Dim 2\")\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.obs.cell_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "neigh_pca = KNeighborsClassifier()\n",
    "df_train = data.obs[data.obs['split'] == 'train']\n",
    "df_test = data.obs[data.obs['split'] == 'test']\n",
    "neigh_pca.fit(pca_train,df_train['cell_type'])\n",
    "y_knn_pca = neigh_pca.predict (pca_test)\n",
    "# print (y_predict)\n",
    "# print (df_pca_test)\n",
    "print (\"PCA accuracy = \", accuracy_score (df_test['cell_type'], y_knn_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_tsne = KNeighborsClassifier()\n",
    "neigh_tsne.fit(tsne_train,df_train['cell_type'])\n",
    "y_knn_tsne = neigh_tsne.predict (tsne_test)\n",
    "print (\"tSNE accuracy = \", accuracy_score (df_test['cell_type'], y_knn_tsne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_umap = KNeighborsClassifier()\n",
    "neigh_umap.fit(umap_train,df_train['cell_type'])\n",
    "y_knn_umap = neigh_umap.predict (umap_test)\n",
    "print (\"UMAP accuracy = \", accuracy_score (df_test['cell_type'], y_knn_umap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_mde = KNeighborsClassifier()\n",
    "neigh_mde.fit(mde_train,df_train['cell_type'])\n",
    "print (mde_train.shape)\n",
    "print (mde_test.shape)\n",
    "y_knn_mde = neigh_mde.predict (mde_test)\n",
    "print (\"MDE accuracy = \", accuracy_score (df_test['cell_type'], y_knn_mde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from matplotlib import pyplot as plt\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# n_components=8\n",
    "# gmm=GaussianMixture(n_components, covariance_type='full', max_iter=100)\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# df_train = data.obs[data.obs['split'] == 'train']\n",
    "# df_test = data.obs[data.obs['split'] == 'test']\n",
    "# gmm.fit(pca_train,df_train['cell_type'])\n",
    "# y_predict_pca = gmm.predict (pca_test)\n",
    "# print(pca_train)\n",
    "# print(df_train['cell_type'])\n",
    "# print(pca_test)\n",
    "# print(df_test['cell_type'])\n",
    "# print(y_predict_pca)\n",
    "\n",
    "# #isinstance(y_predict_pca, np.ndarray)\n",
    "\n",
    "# # # y_predict_pca_list=(y_predict_pca).tolist()\n",
    "# # print(y_predict_pca_list)\n",
    "# replacements = {\n",
    "#     1:'CD4 T',\n",
    "#     2:'CD14 Monocytes',\n",
    "#     3:'B',\n",
    "#     4:'CD8 T',\n",
    "#     5:'NK',\n",
    "#     6:'FCGR3A Monocytes',\n",
    "#     7:'Dendritic',\n",
    "#     8:'Megakaryocytes'\n",
    "# }\n",
    "\n",
    "# p = [replacements.get(x, x) for x in y_predict_pca]\n",
    "# print(p)\n",
    "\n",
    "# arraypca=np.array(p)\n",
    "# print(arraypca)\n",
    "# # printed p and arraypca becuase wasnt sure about what type of structure is p but its also array but seperated with commas \n",
    "# # accuracy is same in both cases as you can see in below output\n",
    "# print (\"PCA accuracy = \", accuracy_score ( p,df_test['cell_type']))\n",
    "# print (\"PCA accuracy = \", accuracy_score (df_test['cell_type'], arraypca))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM accuracy results for pca, tsne ,umap and MDE are poorer than k neighbours.\n",
    "\n",
    "# Also highly variable final accuracy outputs so set seed as 40 as its stochastic .Set n_component as 8 as there are 8 clusters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "n_components=8\n",
    "#random_state=42\n",
    "# gmm=GaussianMixture(n_components, covariance_type='full', max_iter=100)\n",
    "gmm=GaussianMixture(n_components, random_state=40)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_train = data.obs[data.obs['split'] == 'train']\n",
    "df_test = data.obs[data.obs['split'] == 'test']\n",
    "gmm.fit(pca_train,df_train['cell_type'])\n",
    "y_predict_pca = gmm.predict (pca_test)\n",
    "# print(pca_train)\n",
    "# print(df_train['cell_type'])\n",
    "# print(pca_test)\n",
    "# print(df_test['cell_type'])\n",
    "#print(y_predict_pca)\n",
    "\n",
    "#isinstance(y_predict_pca, np.ndarray)\n",
    "\n",
    "# # y_predict_pca_list=(y_predict_pca).tolist()\n",
    "# print(y_predict_pca_list)\n",
    "replacements = {\n",
    "    0:'CD4 T',\n",
    "    1:'CD14 Monocytes',\n",
    "    2:'B',\n",
    "    3:'CD8 T',\n",
    "    4:'NK',\n",
    "    5:'FCGR3A Monocytes',\n",
    "    6:'Dendritic',\n",
    "    7:'Megakaryocytes'\n",
    "}\n",
    "\n",
    "p = [replacements.get(x, x) for x in y_predict_pca]\n",
    "arraypca=np.array(p)\n",
    "\n",
    "print (\"PCA accuracy = \", accuracy_score (df_test['cell_type'], arraypca))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from matplotlib import pyplot as plt\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# n_components=8\n",
    "# gmm=GaussianMixture(n_components, covariance_type='full', max_iter=100)\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# df_train = data.obs[data.obs['split'] == 'train']\n",
    "# df_test = data.obs[data.obs['split'] == 'test']\n",
    "# gmm.fit(pca_train,df_train['cell_type'])\n",
    "# y_predict_pca = gmm.predict (pca_test)\n",
    "# print(pca_train)\n",
    "# print(df_train['cell_type'])\n",
    "# print(pca_test)\n",
    "# print(df_test['cell_type'])\n",
    "# print(y_predict_pca)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print (\"PCA accuracy = \", accuracy_score ( y_predict_pca,df_test['cell_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.fit(tsne_train,df_train['cell_type'])\n",
    "y_predict_tsne = gmm.predict (tsne_test)\n",
    "print(tsne_train)\n",
    "print(tsne_test)\n",
    "print(y_predict_tsne)\n",
    "\n",
    "replacements = {\n",
    "    0:'CD4 T',\n",
    "    1:'CD14 Monocytes',\n",
    "    2:'B',\n",
    "    3:'CD8 T',\n",
    "    4:'NK',\n",
    "    5:'FCGR3A Monocytes',\n",
    "    6:'Dendritic',\n",
    "    7:'Megakaryocytes'\n",
    "}\n",
    "\n",
    "t = [replacements.get(x, x) for x in y_predict_tsne]\n",
    "arraytsne=np.array(t)\n",
    "print (\"tSNE accuracy = \", accuracy_score (df_test['cell_type'], arraytsne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.fit(umap_train,df_train['cell_type'])\n",
    "y_predict_umap = gmm.predict (umap_test)\n",
    "replacements = {\n",
    "    0:'CD4 T',\n",
    "    1:'CD14 Monocytes',\n",
    "    2:'B',\n",
    "    3:'CD8 T',\n",
    "    4:'NK',\n",
    "    5:'FCGR3A Monocytes',\n",
    "    6:'Dendritic',\n",
    "    7:'Megakaryocytes'\n",
    "}\n",
    "\n",
    "u = [replacements.get(x, x) for x in y_predict_umap]\n",
    "\n",
    "\n",
    "arrayumap=np.array(u)\n",
    "\n",
    "\n",
    "print (\"UMAP accuracy = \", accuracy_score (df_test['cell_type'],arrayumap ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.fit(mde_train,df_train['cell_type'])\n",
    "print (mde_train.shape)\n",
    "print (mde_test.shape)\n",
    "y_predict_mde = gmm.predict (mde_test)\n",
    "\n",
    "\n",
    "\n",
    "replacements = {\n",
    "    0:'CD4 T',\n",
    "    1:'CD14 Monocytes',\n",
    "    2:'B',\n",
    "    3:'CD8 T',\n",
    "    4:'NK',\n",
    "    5:'FCGR3A Monocytes',\n",
    "    6:'Dendritic',\n",
    "    7:'Megakaryocytes'\n",
    "}\n",
    "\n",
    "m = [replacements.get(x, x) for x in y_predict_mde]\n",
    "\n",
    "\n",
    "arraymde=np.array(m)\n",
    "\n",
    "\n",
    "print (\"MDE accuracy = \", accuracy_score (df_test['cell_type'], arraymde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # looking at the numpy data\n",
    "# import numpy as np\n",
    "# mde_train = np.load(\"mde_train.npy\")\n",
    "# mde_test = np.load(\"mde_test.npy\")\n",
    "# print(mde_train.shape)\n",
    "# print(mde_train)\n",
    "# print(mde_test.shape)\n",
    "# print(mde_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# from sklearn import mixture\n",
    "# n_components=2\n",
    "# gmm=mixture.GaussianMixture(n_components, covariance_type='full', max_iter=100)\n",
    "# gmm.fit(mde_train)\n",
    "# print(gmm.means_.shape)\n",
    "# print(gmm.means_)\n",
    "# print(gmm.covariances_)\n",
    "# print(gmm.covariances_.shape)\n",
    "# # gmm_predicted_states=gmm_model.predict(mde_test)\n",
    "# gmm_predicted_states=gmm.predict(mde_test)\n",
    "# print(\"printing gmm predicted values\")\n",
    "# print(gmm_predicted_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df_train=pd.DataFrame(mde_train)\n",
    "# plt.scatter(df_train.iloc[:, 0], df_train.iloc[:,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test=pd.DataFrame(mde_test)\n",
    "# plt.scatter(df_test.iloc[:, 0], df_test.iloc[:,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['labels']=gmm_predicted_states\n",
    "# df_0=df_test[df_test['labels']==0]\n",
    "# df_1=df_test[df_test['labels']==1]\n",
    "# plt.figure()\n",
    "# plt.scatter(df_0[0], df_0[1], c='g')\n",
    "# plt.scatter(df_1[0], df_1[1], c='r')\n",
    "\n",
    "# plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from matplotlib import pyplot as plt\n",
    "# from sklearn import mixture\n",
    "# n_components=8\n",
    "# gmm=mixture.GaussianMixture(n_components, covariance_type='full', max_iter=100)\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# df_train = data.obs[data.obs['split'] == 'train']\n",
    "# df_test = data.obs[data.obs['split'] == 'test']\n",
    "# gmm.fit(pca_train,df_train['cell_type'])\n",
    "# y_predict_pca = gmm.predict (pca_test)\n",
    "\n",
    "# print (\"PCA accuracy = \", accuracy_score (df_test['cell_type'], y_predict_pca))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def Heatmap(y_true, y_preds, labels):\n",
    "    \"\"\" Plot the heatmap for prediction\n",
    "    y_true - the true label for each test cell for 10 iterations, should be with length 1800\n",
    "    y_pred - the predict label for each test cell for 10 iterations, should be with length 1800\n",
    "    labels - the order of the labels (unique_labels)\n",
    "    path - file path to save plot (must end with '.eps')\n",
    "    \"\"\"\n",
    "    confusion_array = [confusion_matrix(y_true, y_pred, labels)/10 for y_pred in y_preds]\n",
    "    sb.set(font_scale=1)\n",
    "    \n",
    "    \n",
    "    fig, (ax1, ax2, axcb) = plt.subplots(1, 3, figsize=(12, 6), dpi= 200, gridspec_kw={'width_ratios':[1,1,0.05]})\n",
    "    ax1.get_shared_y_axes().join(ax2)\n",
    "    g1 = sb.heatmap(\n",
    "        confusion_array[0],\n",
    "        cmap=\"Blues\",\n",
    "        cbar=False,\n",
    "        ax=ax1,\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        cbar_kws={\"shrink\": 0.5}\n",
    "    )\n",
    "    g1.set_ylabel('')\n",
    "    g1.set_xlabel('')\n",
    "    g2 = sb.heatmap(\n",
    "        confusion_array[1],\n",
    "        cmap=\"Blues\",\n",
    "        ax=ax2,\n",
    "        cbar_ax=axcb,\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        cbar_kws={\"shrink\": 0.5}\n",
    "    )\n",
    "    g2.set_ylabel('')\n",
    "    g2.set_xlabel('')\n",
    "    g2.set_yticks([])\n",
    "\n",
    "    \n",
    "    # may be needed to rotate the ticklabels correctly:\n",
    "    for ax in [g1,g2]:\n",
    "        tl = ax.get_xticklabels()\n",
    "        ax.set_xticklabels(tl)\n",
    "        tly = ax.get_yticklabels()\n",
    "        ax.set_yticklabels(tly)\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.subplots_adjust(hspace = 0.8)\n",
    "    plt.subplots_adjust(left=0.3)\n",
    "    #plt.xlabel('Predicted Label')\n",
    "    #plt.ylabel('Actual Label')\n",
    "    plt.xticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_ROC_curve(y_true, y_score, ax, color):\n",
    "    total_pos = np.sum(y_true == 1)\n",
    "    total_neg = np.sum(y_true == 0)\n",
    "\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    tpr = np.zeros(100)\n",
    "    fpr = np.zeros(100)\n",
    "    F1_scores = np.zeros(100)\n",
    "    for idx in range(100):\n",
    "        y_hat = (y_score > thresholds[idx]).astype(np.int)\n",
    "        tp = np.logical_and(y_hat == 1, y_true == 1).sum()\n",
    "        fp = np.logical_and(y_hat == 1, y_true == 0).sum()\n",
    "\n",
    "        tp_rate = tp/total_pos\n",
    "        fp_rate = fp/total_neg\n",
    "\n",
    "        if (tp + fp) == 0:\n",
    "            ppv = 0\n",
    "        else:\n",
    "            ppv = tp / (tp + fp)\n",
    "\n",
    "        if ppv == 0:\n",
    "            score = 0\n",
    "        else:\n",
    "            score = 2 * (ppv * tp_rate)/(ppv + tp_rate)\n",
    "\n",
    "        tpr[idx] = tp_rate\n",
    "        fpr[idx] = fp_rate\n",
    "        F1_scores[idx] = score\n",
    "\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, linestyle='solid', color=color, linewidth=3)\n",
    "    return auc, F1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "diag_x, diag_y = [0, 1], [0, 1]\n",
    "ax.plot(diag_x, diag_y, linestyle='dashed', color='#a1d76a', linewidth=3)\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [replacements.get(x, x) for x in y_predict_mde]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique_classes = np.array(df.cell_type.unique(), dtype='<U20')\n",
    "\n",
    "#Heatmap(df_test['cell_type'], arraypca, unique_classes)\n",
    "Heatmap(df_test['cell_type'], [y_knn_pca, arraypca], unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heatmap(df_test['cell_type'], [y_knn_tsne, arraytsne], unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heatmap(df_test['cell_type'], [y_knn_umap, arrayumap], unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heatmap(df_test['cell_type'], [y_knn_mde, arraymde], unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(y, label='CD4 T'):\n",
    "    binarized = (y == label).astype(np.int)\n",
    "    return binarized\n",
    "\n",
    "y_bin = binarize(df_test['cell_type']).values.astype(np.float64)\n",
    "preds = [\n",
    "    neigh_tsne.predict_proba(tsne_test)[:,3],\n",
    "    neigh_umap.predict_proba(umap_test)[:,3],\n",
    "    neigh_mde.predict_proba(mde_test)[:,3]\n",
    "]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "diag_x, diag_y = [0, 1], [0, 1]\n",
    "ax.plot(diag_x, diag_y, linestyle='dashed', color='#a1d76a', linewidth=3)\n",
    "\n",
    "\n",
    "for i, pred in enumerate(preds):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_bin, pred, pos_label=1)\n",
    "\n",
    "    ax.plot(tpr, fpr)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_bin, preds[0], pos_label=1)\n",
    "\n",
    "plt.plot(tpr, fpr)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
